MCP:
    Resources: docs 
    Tools: Tools 
    Prompts: 
    Communication
        Stdio:
        SSE: 
McP host/client (Cursor, Windsurf, Claude): MCP host running MCP client 
    -> method: "tools/call" -> 
MCP server (langraph_query_tool()): locally running server process defined by FastMCP
    -> return 

MCP inspector?




MCP with langchain?
    MCP tool connected to 
    Langraph query tool (a MCP tool)
    Cusor
    Windsurf
    Claude Desktop

Semantic Similarity Search?
Index - Vector Store?

from langchain_core.tools import tool
@tool
def langraph_query_tool(query: str):
    """
    aaaa
    """
    retriever = SkLearnVectorStore(
    embedding=OpenAIEmbeddings(model=)
    persit_path=os.getCwd()
    serializer= 
    )

    relevant_docs=retriever.invoke(query)
    formatted_context=
    return formatted_context

Tools -{bind_tools}-> LangChain ChatModel
Tools -{MCP}-> AI Apps (IDE, Claude Desktop)


Gemini 2.5 update?
Cline?
    API PRovider: Google Gemini
    Gemini API Key: ender here 
    Custom Instructions: 

RooCode?

MCP Motivation:
    In -> AI Agent -> out
        AI Agent -> Context, Tools







.env . -> crearte .env?

python main.py // run a python file

Serper: The world's Festest&Cheapest Google Search API


AI Agent Frameworks
LangChain, AutoGPT, BabyAGI, Cammel, SuperAGI, CrewAI

LangChain
pip install LangChain 
pip install langchain-openai
pip install langain-community

pip install -r requirements.txt
ollama --version
brew upgrade ollama
curl -fsSL https://ollama.com/install.sh | sh
ollama list
python mcp_server.py
python mcp_client.py
ollama pull mistral

python -m venv venv
venv\Scripts\activate

.git/config
    [credential]
	username = SteveKimMHS


How to Build a Local AI Agent With Python (Ollama, LangChain & RAG)
llama3.2 (small)
ollama pull llama3.2
ollama pull mxbai-embed-large


Browser Use: This New AI Agent Can Do Anything (Full AI Scraping Tutorial)
= a Framework = llm controls browser?
pip install browser-use 
playwright install 
main.py
pick an llm?
    claude, antropic, gpt, local llm 
.env file 
    api keys 

External BrowserConfig? 
local browser? 
    chrome_instance_path="/Applications/Google Chrome.App/Contents/MacOs/google Chrome", // executable path

pass the browser to the agent? 

structure out put?
parse information 


